# Comparative-Analysis-of-Phishing-Email-Classifiers
<p align="justify">
In an age where digital communication is the lifeblood of modern society, the battle against email-based threats such as spam, phishing, and their ilk rages on. While email providers like Outlook and Gmail employ algorithms to filter unwanted messages, false positives remain an enduring challenge. Consider, for instance, legitimate emails from educational institutions with essential links, unjustly relegated to the spam folder. The core objective of our project is to advance the state of email classification by meticulously categorizing incoming emails as "safe" or "phishing" while minimizing false positives. We aim to achieve this by extracting language features and computing the similarity between safe and unsafe emails. Our possible future work is to study the causes of a target falling for a phishing attack through an empirical study. Our
present approach includes Exploratory Data Analysis (EDA) for pre-processing, computing the similarity score, and extracting language features using Natural Language Processing (NLP) techniques. Using these features, we will train and test three classifiers - Random Forest, Support Vector, and XGBoost - and present our findings through four experiments to highlight the strengths and weaknesses of each approach.
</p>

### References

1. https://www.kaggle.com/datasets/subhajournal/phishingemails
2. https://www.datacamp.com/tutorial/random-forests-classifier-python
3. https://www.kaggle.com/code/mehmetlaudatekman/text-classification-svm-explained
4. https://www.kaggle.com/code/diveki/classification-with-nlp-xgboost-and-pipelines

### Contributors
1. Prinston Rebello
2. Prateek Giridhar (pgiridha@iu.edu)
3. Ashwin Venkatakrishnan (ashvenk@iu.edu)
